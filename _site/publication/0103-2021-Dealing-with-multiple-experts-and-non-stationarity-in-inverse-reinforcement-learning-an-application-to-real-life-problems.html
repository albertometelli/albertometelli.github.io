

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Dealing with multiple experts and non-stationarity in inverse reinforcement learning: an application to real-life problems - Alberto Maria Metelli, Ph.D.</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Alberto Maria Metelli, Ph.D.">
<meta property="og:title" content="Dealing with multiple experts and non-stationarity in inverse reinforcement learning: an application to real-life problems">


  <link rel="canonical" href="https://albertometelli.github.io/publication/0103-2021-Dealing-with-multiple-experts-and-non-stationarity-in-inverse-reinforcement-learning-an-application-to-real-life-problems">
  <meta property="og:url" content="https://albertometelli.github.io/publication/0103-2021-Dealing-with-multiple-experts-and-non-stationarity-in-inverse-reinforcement-learning-an-application-to-real-life-problems">



  <meta property="og:description" content="Abstract  In real-world applications, inferring the intentions of expert agents (e.g., human operators) can be fundamental to understand how possibly conflicting objectives are managed, helping to interpret the demonstrated behavior. In this paper, we discuss how inverse reinforcement learning (IRL) can be employed to retrieve the reward function implicitly optimized by expert agents acting in real applications. Scaling IRL to real-world cases has proved challenging as typically only a fixed dataset of demonstrations is available and further interactions with the environment are not allowed. For this reason, we resort to a class of truly batch model-free IRL algorithms and we present three application scenarios: (1) the high-level decision-making problem in the highway driving scenario, and (2) inferring the user preferences in a social network (Twitter), and (3) the management of the water release in the Como Lake. For each of these scenarios, we provide formalization, experiments and a discussion to interpret the obtained results. ">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2021-01-01T00:00:00+01:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Alberto Maria Metelli",
      "url" : "https://albertometelli.github.io",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://albertometelli.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Alberto Maria Metelli, Ph.D. Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://albertometelli.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="https://albertometelli.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="https://albertometelli.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="https://albertometelli.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="https://albertometelli.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="https://albertometelli.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="https://albertometelli.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="https://albertometelli.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="https://albertometelli.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="https://albertometelli.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="https://albertometelli.github.io/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="https://albertometelli.github.io/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="https://albertometelli.github.io/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="https://albertometelli.github.io/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="https://albertometelli.github.io/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="https://albertometelli.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="https://albertometelli.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="https://albertometelli.github.io/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="https://albertometelli.github.io/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://albertometelli.github.io/">Alberto Maria Metelli, Ph.D.</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/about/">About Me</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/news/">News</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/contacts/">Contacts</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="https://albertometelli.github.io/images/profile3.png" class="author__avatar" alt="Alberto Maria Metelli">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Alberto Maria Metelli</h3>
    <p class="author__bio">Postdoctoral Researcher at Politecnico di Milano</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Milan, Italy</li>
      
      
      
      
      
        <li><a href="https://www.deib.polimi.it/eng/people/details/926910"><i class="fa fa-university"></i> Institutional Page</a></li>
      
      
        <li><a href="https://www.linkedin.com/in/alberto-maria-metelli-01504214b"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
      
      
        <li><a href="https://twitter.com/alberto_metelli"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
        <li><a href="https://github.com/albertometelli"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.it/citations?user=R31IsPwAAAAJ&hl=en"><i class="ai ai-google-scholar ai"></i> Google Scholar</a></li>
      
      <!--
      
        <li><a href="https://www.researchgate.net/profile/Alberto_Maria_Metelli"><i class="ai ai-researchgate ai" aria-hidden="true"></i> ResearchGate</a></li>
      
      
      
        <li><a href="https://orcid.org/0000-0002-3424-5212"><i class="ai ai-orcid ai"></i> ORCID</a></li>
      
      
      
	  
        <li><a href="https://dblp.org/pid/209/4941.html"><i class="ai ai-dblp ai"></i> dblp</a></li>
      
      
        <li><a href="https://www.scopus.com/authid/detail.uri?authorId=57195947711"><i class="ai ai-scopus ai"></i> Scopus</a></li>
      
      -->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Dealing with multiple experts and non-stationarity in inverse reinforcement learning: an application to real-life problems">
    <meta itemprop="description" content="Abstract  In real-world applications, inferring the intentions of expert agents (e.g., human operators) can be fundamental to understand how possibly conflicting objectives are managed, helping to interpret the demonstrated behavior. In this paper, we discuss how inverse reinforcement learning (IRL) can be employed to retrieve the reward function implicitly optimized by expert agents acting in real applications. Scaling IRL to real-world cases has proved challenging as typically only a fixed dataset of demonstrations is available and further interactions with the environment are not allowed. For this reason, we resort to a class of truly batch model-free IRL algorithms and we present three application scenarios: (1) the high-level decision-making problem in the highway driving scenario, and (2) inferring the user preferences in a social network (Twitter), and (3) the management of the water release in the Como Lake. For each of these scenarios, we provide formalization, experiments and a discussion to interpret the obtained results. ">
    <meta itemprop="datePublished" content="January 01, 2021">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Dealing with multiple experts and non-stationarity in inverse reinforcement learning: an application to real-life problems
</h1>
          
        
        
        
			<p><b> Amarildo  Likmeta,  Alberto Maria Metelli,  Giorgia  Ramponi,  Andrea  Tirinzoni,  Matteo  Giuliani, and  Marcello  Restelli</b></p> 
		
        
        
          <p><i>Machine Learning</i>, 2021.
		  
		  </p>
          
          <p>
          
          
          
			<b>CORE 2020: A</b>&emsp;&emsp;
          
          
          
			<b>SJR 2020: Q1</b>&emsp;&emsp;
          
          
          
          </p>
          
          
        
        
             
        <!--
          <p>Recommended citation:  Amarildo  Likmeta,  Alberto Maria Metelli,  Giorgia  Ramponi,  Andrea  Tirinzoni,  Matteo  Giuliani, and  Marcello  Restelli&quot;Dealing with multiple experts and non-stationarity in inverse reinforcement learning: an application to real-life problems.&quot; Machine Learning, 2021 <a href="https://doi.org/10.1007/s10994-020-05939-8"><u>https://doi.org/10.1007/s10994-020-05939-8</u></a></p>
        -->
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p>Abstract
 <br /> In real-world applications, inferring the intentions of expert agents (e.g., human operators) can be fundamental to understand how possibly conflicting objectives are managed, helping to interpret the demonstrated behavior. In this paper, we discuss how inverse reinforcement learning (IRL) can be employed to retrieve the reward function implicitly optimized by expert agents acting in real applications. Scaling IRL to real-world cases has proved challenging as typically only a fixed dataset of demonstrations is available and further interactions with the environment are not allowed. For this reason, we resort to a class of truly batch model-free IRL algorithms and we present three application scenarios: (1) the high-level decision-making problem in the highway driving scenario, and (2) inferring the user preferences in a social network (Twitter), and (3) the management of the water release in the Como Lake. For each of these scenarios, we provide formalization, experiments and a discussion to interpret the obtained results. <br /></p>

<p>[<a href="https://doi.org/10.1007/s10994-020-05939-8" target="_blank">Link</a>] [<a href="/files/bibtex/likmeta2021dealing.bib" target="_blank">BibTeX</a>]</p>
<pre> @Article{likmeta2021dealing,
    author = "Likmeta, Amarildo and Metelli, Alberto Maria and Ramponi, Giorgia and Tirinzoni, Andrea and Giuliani, Matteo and Restelli, Marcello",
    title = "Dealing with multiple experts and non-stationarity in inverse reinforcement learning: an application to real-life problems",
    journal = "Machine Learning",
    volume = "110",
    number = "9",
    pages = "2541--2576",
    year = "2021",
    url = "https://doi.org/10.1007/s10994-020-05939-8",
    doi = "https://doi.org/10.1007/s10994-020-05939-8"
} </pre>

        
      </section>
      
      <footer class="page__meta">
        
        




      </footer>

      

      


  <nav class="pagination">
    
      <a href="https://albertometelli.github.io/publication/0013-2021-Subgaussian-and-Differentiable-Importance-Sampling-for-Off-Policy-Evaluation-and-Learning" class="pagination--pager" title="Subgaussian and Differentiable Importance Sampling for Off-Policy Evaluation and Learning
">Previous</a>
    
    
      <a href="https://albertometelli.github.io/publication/0104-2021-Safe-Policy-Iteration-A-Monotonically-Improving-Approximate-Policy-Iteration-Approach" class="pagination--pager" title="Safe Policy Iteration: A Monotonically Improving Approximate Policy Iteration Approach
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<!--<a href="/sitemap/">Sitemap</a> -->
<!-- end custom footer snippets -->

        

<div class="page__footer-copyright">&copy; 2022 Alberto Maria Metelli. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="https://albertometelli.github.io/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

