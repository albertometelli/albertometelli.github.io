

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Handling Non-Stationary Experts in Inverse Reinforcement Learning: A Water System Control Case Study - Alberto Maria Metelli, Ph.D.</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Alberto Maria Metelli, Ph.D.">
<meta property="og:title" content="Handling Non-Stationary Experts in Inverse Reinforcement Learning: A Water System Control Case Study">


  <link rel="canonical" href="https://albertometelli.github.io/publication/0201-2020-Handling-Non-Stationary-Experts-in-Inverse-Reinforcement-Learning-A-Water-System-Control-Case-Study">
  <meta property="og:url" content="https://albertometelli.github.io/publication/0201-2020-Handling-Non-Stationary-Experts-in-Inverse-Reinforcement-Learning-A-Water-System-Control-Case-Study">



  <meta property="og:description" content="Abstract  One of the challenges for applying Reinforcement Learning (RL) in real-world scenarios is the absence of a formalized reward signal, especially in presence of multiple, possibly conflicting, objectives. However, observational data of many real systems are nowadays available, providing demonstrations from experts (e.g., human operators) that can be used in Inverse Reinforcement Learning (IRL) to formalize the observed task in an RL fashion. In this paper, we address the problem of inferring the preferences of the historical operation of Lake Como.In this case study, no interaction with the environment is allowed, and only a fixed dataset of demonstrations is available. Moreover, the expert is non-stationary since its intentions change during decades when exposed to changing external forces. For this reason, we propose an extension of the batch model-free algorithm Σ-GIRL to the non-stationary case. For the Lake Como scenario we provide formalization, experiments and a discussion to interpret the obtained results. ">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2020-01-01T00:00:00+01:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Alberto Maria Metelli",
      "url" : "https://albertometelli.github.io",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://albertometelli.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Alberto Maria Metelli, Ph.D. Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://albertometelli.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="https://albertometelli.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="https://albertometelli.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="https://albertometelli.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="https://albertometelli.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="https://albertometelli.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="https://albertometelli.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="https://albertometelli.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="https://albertometelli.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="https://albertometelli.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="https://albertometelli.github.io/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="https://albertometelli.github.io/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="https://albertometelli.github.io/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="https://albertometelli.github.io/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="https://albertometelli.github.io/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="https://albertometelli.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="https://albertometelli.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="https://albertometelli.github.io/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="https://albertometelli.github.io/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://albertometelli.github.io/">Alberto Maria Metelli, Ph.D.</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/about/">About Me</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/news/">News</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://albertometelli.github.io/contacts/">Contacts</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="https://albertometelli.github.io/images/profile3.png" class="author__avatar" alt="Alberto Maria Metelli">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Alberto Maria Metelli</h3>
    <p class="author__bio">Postdoctoral Researcher at Politecnico di Milano</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Milan, Italy</li>
      
      
      
      
      
        <li><a href="https://www.deib.polimi.it/eng/people/details/926910"><i class="fa fa-university"></i> Institutional Page</a></li>
      
      
        <li><a href="https://www.linkedin.com/in/alberto-maria-metelli-01504214b"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
      
      
        <li><a href="https://twitter.com/alberto_metelli"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
        <li><a href="https://github.com/albertometelli"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.it/citations?user=R31IsPwAAAAJ&hl=en"><i class="ai ai-google-scholar ai"></i> Google Scholar</a></li>
      
      <!--
      
        <li><a href="https://www.researchgate.net/profile/Alberto_Maria_Metelli"><i class="ai ai-researchgate ai" aria-hidden="true"></i> ResearchGate</a></li>
      
      
      
        <li><a href="https://orcid.org/0000-0002-3424-5212"><i class="ai ai-orcid ai"></i> ORCID</a></li>
      
      
      
	  
        <li><a href="https://dblp.org/pid/209/4941.html"><i class="ai ai-dblp ai"></i> dblp</a></li>
      
      
        <li><a href="https://www.scopus.com/authid/detail.uri?authorId=57195947711"><i class="ai ai-scopus ai"></i> Scopus</a></li>
      
      -->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Handling Non-Stationary Experts in Inverse Reinforcement Learning: A Water System Control Case Study">
    <meta itemprop="description" content="Abstract  One of the challenges for applying Reinforcement Learning (RL) in real-world scenarios is the absence of a formalized reward signal, especially in presence of multiple, possibly conflicting, objectives. However, observational data of many real systems are nowadays available, providing demonstrations from experts (e.g., human operators) that can be used in Inverse Reinforcement Learning (IRL) to formalize the observed task in an RL fashion. In this paper, we address the problem of inferring the preferences of the historical operation of Lake Como.In this case study, no interaction with the environment is allowed, and only a fixed dataset of demonstrations is available. Moreover, the expert is non-stationary since its intentions change during decades when exposed to changing external forces. For this reason, we propose an extension of the batch model-free algorithm Σ-GIRL to the non-stationary case. For the Lake Como scenario we provide formalization, experiments and a discussion to interpret the obtained results. ">
    <meta itemprop="datePublished" content="January 01, 2020">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Handling Non-Stationary Experts in Inverse Reinforcement Learning: A Water System Control Case Study
</h1>
          
        
        
        
			<p><b> Amarildo  Likmeta,  Alberto Maria Metelli,  Giorgia  Ramponi,  Andrea  Tirinzoni,  Matteo  Giuliani, and  Marcello  Restelli</b></p> 
		
        
        
          <p><i>Challenges of Real-World RL Workshop @ NeurIPS 2020</i>, 2020.
		  
		  </p>
          
          <p>
          
          
          
          
          
          
          
          </p>
          
          
        
        
             
        <!--
          <p>Recommended citation:  Amarildo  Likmeta,  Alberto Maria Metelli,  Giorgia  Ramponi,  Andrea  Tirinzoni,  Matteo  Giuliani, and  Marcello  Restelli&quot;Handling Non-Stationary Experts in Inverse Reinforcement Learning: A Water System Control Case Study.&quot; Challenges of Real-World RL Workshop @ NeurIPS 2020, 2020. <a href="https://drive.google.com/file/d/1v3CiRlWtOVJZry15DQdxzeh98UoNAWbA/view"><u>https://drive.google.com/file/d/1v3CiRlWtOVJZry15DQdxzeh98UoNAWbA/view</u></a></p>
        -->
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p>Abstract
 <br /> One of the challenges for applying Reinforcement Learning (RL) in real-world scenarios is the absence of a formalized reward signal, especially in presence of multiple, possibly conflicting, objectives. However, observational data of many real systems are nowadays available, providing demonstrations from experts (e.g., human operators) that can be used in Inverse Reinforcement Learning (IRL) to formalize the observed task in an RL fashion. In this paper, we address the problem of inferring the preferences of the historical operation of Lake Como.In this case study, no interaction with the environment is allowed, and only a fixed dataset of demonstrations is available. Moreover, the expert is non-stationary since its intentions change during decades when exposed to changing external forces. For this reason, we propose an extension of the batch model-free algorithm Σ-GIRL to the non-stationary case. For the Lake Como scenario we provide formalization, experiments and a discussion to interpret the obtained results. <br /></p>

<p>[<a href="https://drive.google.com/file/d/1v3CiRlWtOVJZry15DQdxzeh98UoNAWbA/view" target="_blank">Paper</a>] [<a href="https://slideslive.com/38943284/handling-nonstationary-experts-in-inverse-reinforcement-learning-a-water-system-control-case-study" target="_blank">Talk</a>] [<a href="/files/bibtex/likmeta2020handling.bib" target="_blank">BibTeX</a>]</p>
<pre> @article{likmeta2020handling,
    author = "Likmeta, Amarildo and Metelli, Alberto Maria and Ramponi, Giorgia and Tirinzoni, Andrea and Giuliani, Matteo and Restelli, Marcello",
    title = "Handling Non-Stationary Experts in Inverse Reinforcement Learning: A Water System Control Case Study",
    journal = "Challenges of Real-World RL Workshop @ NeurIPS 2020",
    year = "2020",
    url = "https://drive.google.com/file/d/1v3CiRlWtOVJZry15DQdxzeh98UoNAWbA/view"
} </pre>

        
      </section>
      
      <footer class="page__meta">
        
        




      </footer>

      

      


  <nav class="pagination">
    
      <a href="https://albertometelli.github.io/publication/0102-2020-Importance-Sampling-Techniques-for-Policy-Optimization" class="pagination--pager" title="Importance Sampling Techniques for Policy Optimization
">Previous</a>
    
    
      <a href="https://albertometelli.github.io/publication/0202-2020-Autonomous-Driving-with-Reinforcement-Learning-and-Rule-based-Policies" class="pagination--pager" title="Autonomous Driving with Reinforcement Learning and Rule-based Policies
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<!--<a href="/sitemap/">Sitemap</a> -->
<!-- end custom footer snippets -->

        

<div class="page__footer-copyright">&copy; 2022 Alberto Maria Metelli. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="https://albertometelli.github.io/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

