<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://albertometelli.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://albertometelli.github.io/" rel="alternate" type="text/html" /><updated>2022-02-20T11:02:00+01:00</updated><id>https://albertometelli.github.io/feed.xml</id><title type="html">Alberto Maria Metelli, Ph.D.</title><subtitle>personal description</subtitle><author><name>Alberto Maria Metelli</name></author><entry><title type="html">Premio NeoDottori di Ricerca &quot;Marco Cadoli&quot; 2021</title><link href="https://albertometelli.github.io/posts/2021/12/aixia/" rel="alternate" type="text/html" title="Premio NeoDottori di Ricerca &amp;quot;Marco Cadoli&amp;quot; 2021" /><published>2021-12-02T00:00:00+01:00</published><updated>2021-12-02T00:00:00+01:00</updated><id>https://albertometelli.github.io/posts/2021/12/aixia</id><content type="html" xml:base="https://albertometelli.github.io/posts/2021/12/aixia/">&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Honored that my Ph.D. thesis was awarded with the &amp;quot;Premio NeoDottori di Ricerca &amp;quot;Marco Cadoli&amp;quot; 2021&amp;quot;, by &lt;a href=&quot;https://twitter.com/AI_x_IA?ref_src=twsrc%5Etfw&quot;&gt;@AI_x_IA&lt;/a&gt;, for the best Italian doctoral thesis in &lt;a href=&quot;https://twitter.com/hashtag/AI?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#AI&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;This is the result of three beautiful years of research at &lt;a href=&quot;https://twitter.com/polimi?ref_src=twsrc%5Etfw&quot;&gt;@polimi&lt;/a&gt; under the supervision of Marcello Restelli. &lt;a href=&quot;https://t.co/5IaV9Lp4lB&quot;&gt;pic.twitter.com/5IaV9Lp4lB&lt;/a&gt;&lt;/p&gt;&amp;mdash; Alberto Maria Metelli (@alberto_metelli) &lt;a href=&quot;https://twitter.com/alberto_metelli/status/1466497946355216384?ref_src=twsrc%5Etfw&quot;&gt;December 2, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="AIxIA" /><summary type="html">Honored that my Ph.D. thesis was awarded with the &amp;quot;Premio NeoDottori di Ricerca &amp;quot;Marco Cadoli&amp;quot; 2021&amp;quot;, by @AI_x_IA, for the best Italian doctoral thesis in #AI. This is the result of three beautiful years of research at @polimi under the supervision of Marcello Restelli. pic.twitter.com/5IaV9Lp4lB&amp;mdash; Alberto Maria Metelli (@alberto_metelli) December 2, 2021</summary></entry><entry><title type="html">One Paper accepted at AAAI 2021</title><link href="https://albertometelli.github.io/posts/2020/12/aaai2021/" rel="alternate" type="text/html" title="One Paper accepted at AAAI 2021" /><published>2020-12-02T00:00:00+01:00</published><updated>2020-12-02T00:00:00+01:00</updated><id>https://albertometelli.github.io/posts/2020/12/aaai2021</id><content type="html" xml:base="https://albertometelli.github.io/posts/2020/12/aaai2021/">&lt;p&gt;Our paper &lt;b&gt;&lt;a href=&quot;/publication/0011-2021-Policy-Optimization-as-Online-Learning-with-Mediator-Feedback&quot;&gt;Policy Optimization as Online Learning with Mediator Feedback&lt;/a&gt;&lt;/b&gt; has been accepted for publication in AAAI 2021!&lt;/p&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="AAAI 2021" /><summary type="html">Our paper Policy Optimization as Online Learning with Mediator Feedback has been accepted for publication in AAAI 2021!</summary></entry><entry><title type="html">One Paper accepted for JMLR</title><link href="https://albertometelli.github.io/posts/2020/01/jmlr2020/" rel="alternate" type="text/html" title="One Paper accepted for JMLR" /><published>2020-07-06T00:00:00+02:00</published><updated>2020-07-06T00:00:00+02:00</updated><id>https://albertometelli.github.io/posts/2020/01/jmlr2020</id><content type="html" xml:base="https://albertometelli.github.io/posts/2020/01/jmlr2020/">&lt;p&gt;Our paper &lt;b&gt;&lt;a href=&quot;/publication/0102-2020-Importance-Sampling-Techniques-for-Policy-Optimization&quot;&gt;Importance Sampling Techniques for Policy Optimization&lt;/a&gt;&lt;/b&gt; has been accepted for publication in JMLR!&lt;/p&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="JMLR" /><summary type="html">Our paper Importance Sampling Techniques for Policy Optimization has been accepted for publication in JMLR!</summary></entry><entry><title type="html">One Paper accepted at ICML 2020</title><link href="https://albertometelli.github.io/posts/2020/01/icml2020/" rel="alternate" type="text/html" title="One Paper accepted at ICML 2020" /><published>2020-06-02T00:00:00+02:00</published><updated>2020-06-02T00:00:00+02:00</updated><id>https://albertometelli.github.io/posts/2020/01/icml2020</id><content type="html" xml:base="https://albertometelli.github.io/posts/2020/01/icml2020/">&lt;p&gt;Our paper &lt;b&gt;&lt;a href=&quot;/publication/0010-2020-Control-Frequency-Adaptation-via-Action-Persistence-in-Batch-Reinforcement-Learning&quot;&gt;Control Frequency Adaptation via Action Persistence in Batch Reinforcement Learning&lt;/a&gt;&lt;/b&gt; has been accepted for publication at ICML 2020!&lt;/p&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="ICML 2020" /><summary type="html">Our paper Control Frequency Adaptation via Action Persistence in Batch Reinforcement Learning has been accepted for publication at ICML 2020!</summary></entry><entry><title type="html">One Paper accepted at AAAI 2020</title><link href="https://albertometelli.github.io/posts/2019/11/aaai2020/" rel="alternate" type="text/html" title="One Paper accepted at AAAI 2020" /><published>2019-11-10T00:00:00+01:00</published><updated>2019-11-10T00:00:00+01:00</updated><id>https://albertometelli.github.io/posts/2019/11/aaai2020</id><content type="html" xml:base="https://albertometelli.github.io/posts/2019/11/aaai2020/">&lt;p&gt;Our paper &lt;b&gt;&lt;a href=&quot;/publication/0008-2020-Gradient-Aware-Model-Based-Policy-Search&quot;&gt;Gradient Aware Model-based Policy Search&lt;/a&gt;&lt;/b&gt; has been accepted for publication at AAAI 2020!&lt;/p&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="AAAI 2020" /><summary type="html">Our paper Gradient Aware Model-based Policy Search has been accepted for publication at AAAI 2020!</summary></entry><entry><title type="html">One Paper accepted at NeurIPS 2019</title><link href="https://albertometelli.github.io/posts/2019/09/neurips2019/" rel="alternate" type="text/html" title="One Paper accepted at NeurIPS 2019" /><published>2019-09-04T00:00:00+02:00</published><updated>2019-09-04T00:00:00+02:00</updated><id>https://albertometelli.github.io/posts/2019/09/neurips2019</id><content type="html" xml:base="https://albertometelli.github.io/posts/2019/09/neurips2019/">&lt;p&gt;Our paper &lt;b&gt;&lt;a href=&quot;/publication/0007-2019-Propagating-Uncertainty-in-Reinforcement-Learning-via-Wasserstein-Barycenters&quot;&gt;Propagating Uncertainty in Reinforcement Learning via Wasserstein Barycenters&lt;/a&gt;&lt;/b&gt; has been accepted for publication at NeurIPS 2019!&lt;/p&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="NeurIPS 2019" /><summary type="html">Our paper Propagating Uncertainty in Reinforcement Learning via Wasserstein Barycenters has been accepted for publication at NeurIPS 2019!</summary></entry><entry><title type="html">Two Papers accepted at ICML 2019</title><link href="https://albertometelli.github.io/posts/2019/04/icml2019/" rel="alternate" type="text/html" title="Two Papers accepted at ICML 2019" /><published>2019-04-22T00:00:00+02:00</published><updated>2019-04-22T00:00:00+02:00</updated><id>https://albertometelli.github.io/posts/2019/04/icml2019</id><content type="html" xml:base="https://albertometelli.github.io/posts/2019/04/icml2019/">&lt;p&gt;My colleagues and I got two papers accepted at ICML 2019: &lt;b&gt;&lt;a href=&quot;/publication/0005-2019-Reinforcement-Learning-in-Configurable-Continuous-Environments&quot;&gt;Reinforcement Learning in Configurable Continuous Environments&lt;/a&gt;&lt;/b&gt; and &lt;b&gt;&lt;a href=&quot;/publication/0004-2019-Optimistic-Policy-Optimization-via-Multiple-Importance-Sampling&quot;&gt;Optimistic Policy Optimization via Multiple Importance Sampling&lt;/a&gt;&lt;/b&gt;!&lt;/p&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="ICML 2019" /><summary type="html">My colleagues and I got two papers accepted at ICML 2019: Reinforcement Learning in Configurable Continuous Environments and Optimistic Policy Optimization via Multiple Importance Sampling!</summary></entry><entry><title type="html">Our Paper POIS has been accepted for Oral Presentation at NeurIPS 2018</title><link href="https://albertometelli.github.io/posts/2018/09/neurips2018/" rel="alternate" type="text/html" title="Our Paper POIS has been accepted for Oral Presentation at NeurIPS 2018" /><published>2018-09-04T00:00:00+02:00</published><updated>2018-09-04T00:00:00+02:00</updated><id>https://albertometelli.github.io/posts/2018/09/neurips2018</id><content type="html" xml:base="https://albertometelli.github.io/posts/2018/09/neurips2018/">&lt;p&gt;Our paper &lt;b&gt;&lt;a href=&quot;/publication/0002-2018-Policy-Optimization-via-Importance-Sampling&quot;&gt;Policy Optimization via Importance Sampling&lt;/a&gt;&lt;/b&gt; has been accepted for &lt;b&gt;oral presentation&lt;/b&gt; at NeurIPS 2018!&lt;/p&gt;

&lt;p&gt;Watch the &lt;a href=&quot;https://www.facebook.com/nipsfoundation/videos/198568127715251/&quot;&gt;Talk&lt;/a&gt; given by my colleague &lt;a href=&quot;https://t3p.github.io/&quot;&gt;Matteo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/poislogo.png&quot; /&gt;&lt;/p&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="NeurIPS 2018" /><summary type="html">Our paper Policy Optimization via Importance Sampling has been accepted for oral presentation at NeurIPS 2018!</summary></entry><entry><title type="html">One Paper accepted at ICML 2018</title><link href="https://albertometelli.github.io/posts/2018/05/icml2018/" rel="alternate" type="text/html" title="One Paper accepted at ICML 2018" /><published>2018-05-01T00:00:00+02:00</published><updated>2018-05-01T00:00:00+02:00</updated><id>https://albertometelli.github.io/posts/2018/05/icml2018</id><content type="html" xml:base="https://albertometelli.github.io/posts/2018/05/icml2018/">&lt;p&gt;Our paper &lt;b&gt;&lt;a href=&quot;/publication/0003-2018-Configurable-Markov-Decision-Processes&quot;&gt;Configurable Markov Decision Processes&lt;/a&gt;&lt;/b&gt; is going to be presented at ICML 2018 in a long talk.&lt;/p&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="ICML 2018" /><summary type="html">Our paper Configurable Markov Decision Processes is going to be presented at ICML 2018 in a long talk.</summary></entry><entry><title type="html">One Paper accepted at NIPS 2017</title><link href="https://albertometelli.github.io/posts/2017/09/nips2017/" rel="alternate" type="text/html" title="One Paper accepted at NIPS 2017" /><published>2017-09-30T00:00:00+02:00</published><updated>2017-09-30T00:00:00+02:00</updated><id>https://albertometelli.github.io/posts/2017/09/nips2017</id><content type="html" xml:base="https://albertometelli.github.io/posts/2017/09/nips2017/">&lt;p&gt;Our paper &lt;b&gt;&lt;a href=&quot;/publication/0001-2017-Compatible-Reward-Inverse-Reinforcement-Learning&quot;&gt;Compatible Reward Inverse Reinforcement Learning&lt;/a&gt;&lt;/b&gt; has been accepted for publication at NIPS 2017!&lt;/p&gt;</content><author><name>Alberto Maria Metelli</name></author><category term="NeurIPS 2017" /><summary type="html">Our paper Compatible Reward Inverse Reinforcement Learning has been accepted for publication at NIPS 2017!</summary></entry></feed>